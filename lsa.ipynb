{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"Human machine interface for lab computer applications\",\n",
    "             \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",\n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "             \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "             \"Graph minors A survey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Human machine interface for lab computer applications', 'A survey of user opinion of computer system response time', 'The EPS user interface management system', 'System and human system engineering testing of EPS', 'Relation of user perceived response time to error measurement', 'The generation of random binary unordered trees', 'The intersection graph of paths in trees', 'Graph minors IV Widths of trees and well quasi ordering', 'Graph minors A survey']\n"
    }
   ],
   "source": [
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove common words and tokenize them\n",
    "stoplist = set('for a of the and to in'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [[word for word in document.lower().split() if word not in stoplist] for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[['human', 'machine', 'interface', 'lab', 'computer', 'applications'], ['survey', 'user', 'opinion', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'management', 'system'], ['system', 'human', 'system', 'engineering', 'testing', 'eps'], ['relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement'], ['generation', 'random', 'binary', 'unordered', 'trees'], ['intersection', 'graph', 'paths', 'trees'], ['graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering'], ['graph', 'minors', 'survey']]\n"
    }
   ],
   "source": [
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['human', 'machine', 'interface', 'lab', 'computer', 'applications', 'survey', 'user', 'opinion', 'computer', 'system', 'response', 'time', 'eps', 'user', 'interface', 'management', 'system', 'system', 'human', 'system', 'engineering', 'testing', 'eps', 'relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement', 'generation', 'random', 'binary', 'unordered', 'trees', 'intersection', 'graph', 'paths', 'trees', 'graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering', 'graph', 'minors', 'survey']\n"
    }
   ],
   "source": [
    "# remove words those appear only once\n",
    "all_tokens = sum(texts, [])\n",
    "\n",
    "print(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'testing', 'generation', 'error', 'binary', 'lab', 'well', 'applications', 'relation', 'engineering', 'quasi', 'unordered', 'measurement', 'random', 'opinion', 'management', 'machine', 'perceived', 'iv', 'widths', 'ordering', 'paths', 'intersection'}\n"
    }
   ],
   "source": [
    "tokens_once = set(word for word in set(all_tokens) if all_tokens.count(word) ==1)\n",
    "\n",
    "print(tokens_once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[['human', 'interface', 'computer'], ['survey', 'user', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'system'], ['system', 'human', 'system', 'eps'], ['user', 'response', 'time'], ['trees'], ['graph', 'trees'], ['graph', 'minors', 'trees'], ['graph', 'minors', 'survey']]\n"
    }
   ],
   "source": [
    "texts = [[word for word in text if word not in tokens_once]\n",
    "         for text in texts]\n",
    "\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...)\n"
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.save('deerwester.dict')  # save as binary file at the dictionary at local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.save_as_text('deerwester_text.dict')  # save as text file at the local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'computer': 0, 'human': 1, 'interface': 2, 'response': 3, 'survey': 4, 'system': 5, 'time': 6, 'user': 7, 'eps': 8, 'trees': 9, 'graph': 10, 'minors': 11}\n"
    }
   ],
   "source": [
    "print(dictionary.token2id) # show pairs of \"word : word-ID number\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[(0, 1), (1, 1)]\n"
    }
   ],
   "source": [
    "new_doc = \"Human computer interaction\" # temporary data to see role of below function\n",
    "\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split()) # return \"word-ID : Frequency of appearance\"\"\n",
    "print(new_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[(0, 1), (1, 1), (2, 1)], [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)], [(2, 1), (5, 1), (7, 1), (8, 1)], [(1, 1), (5, 2), (8, 1)], [(3, 1), (6, 1), (7, 1)], [(9, 1)], [(9, 1), (10, 1)], [(9, 1), (10, 1), (11, 1)], [(4, 1), (10, 1), (11, 1)]]\n"
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora.MmCorpus.serialize('deerwester.mm', corpus) # save corpus at local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[(0, 1.0), (1, 1.0), (2, 1.0)], [(0, 1.0), (3, 1.0), (4, 1.0), (5, 1.0), (6, 1.0), (7, 1.0)], [(2, 1.0), (5, 1.0), (7, 1.0), (8, 1.0)], [(1, 1.0), (5, 2.0), (8, 1.0)], [(3, 1.0), (6, 1.0), (7, 1.0)], [(9, 1.0)], [(9, 1.0), (10, 1.0)], [(9, 1.0), (10, 1.0), (11, 1.0)], [(4, 1.0), (10, 1.0), (11, 1.0)]]\n"
    }
   ],
   "source": [
    "corpus = corpora.MmCorpus('deerwester.mm') # try to load the saved corpus from local\n",
    "\n",
    "print(list(corpus)) # to show corpus which was read above, need to print(list( )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...)\n"
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary.load('deerwester.dict') # try to load saved dic.from local\n",
    "\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MmCorpus(9 documents, 12 features, 28 non-zero entries)\n"
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "TfidfModel(num_docs=9, num_nnz=28)\n"
    }
   ],
   "source": [
    "tfidf = models.TfidfModel(corpus) # step 1 -- initialize a model\n",
    "\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<gensim.interfaces.TransformedCorpus object at 0x000001648475BA90>\n"
    }
   ],
   "source": [
    "corpus_tfidf = tfidf[corpus]  # map corpus object into tfidf space\n",
    "\n",
    "print(corpus_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[(0, 0.5773502691896257), (1, 0.5773502691896257), (2, 0.5773502691896257)]\n[(0, 0.44424552527467476), (3, 0.44424552527467476), (4, 0.44424552527467476), (5, 0.3244870206138555), (6, 0.44424552527467476), (7, 0.3244870206138555)]\n[(2, 0.5710059809418182), (5, 0.4170757362022777), (7, 0.4170757362022777), (8, 0.5710059809418182)]\n[(1, 0.49182558987264147), (5, 0.7184811607083769), (8, 0.49182558987264147)]\n[(3, 0.6282580468670046), (6, 0.6282580468670046), (7, 0.45889394536615247)]\n[(9, 1.0)]\n[(9, 0.7071067811865475), (10, 0.7071067811865475)]\n[(9, 0.5080429008916749), (10, 0.5080429008916749), (11, 0.695546419520037)]\n[(4, 0.6282580468670046), (10, 0.45889394536615247), (11, 0.6282580468670046)]\n"
    }
   ],
   "source": [
    "for doc in corpus_tfidf: # show tfidf-space mapped words\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "LsiModel(num_terms=12, num_topics=2, decay=1.0, chunksize=20000)\n"
    }
   ],
   "source": [
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2) # initialize LSI \n",
    "print(lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<gensim.interfaces.TransformedCorpus object at 0x00000164847621D0>\n"
    }
   ],
   "source": [
    "corpus_lsi = lsi[corpus_tfidf] # create a double wrapper over the original corpus\n",
    "print(corpus_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = lsi.print_topics(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[(0, '0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"time\" + 0.060*\"response\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"'), (1, '-0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"response\" + -0.320*\"time\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"')]\n"
    }
   ],
   "source": [
    "print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[(0, 0.06600783396090415), (1, -0.5200703306361851)]\n[(0, 0.19667592859142394), (1, -0.7609563167700049)]\n[(0, 0.08992639972446434), (1, -0.724186062675251)]\n[(0, 0.075858476521782), (1, -0.6320551586003429)]\n[(0, 0.10150299184979994), (1, -0.5737308483002957)]\n[(0, 0.7032108939378315), (1, 0.16115180214025768)]\n[(0, 0.8774787673119835), (1, 0.1675890686465937)]\n[(0, 0.9098624686818579), (1, 0.14086553628718967)]\n[(0, 0.6165825350569278), (1, -0.05392907566389409)]\n"
    }
   ],
   "source": [
    "for doc in corpus_lsi:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi.save('model.lsi')  # save output model at local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "LsiModel(num_terms=12, num_topics=2, decay=1.0, chunksize=20000)\n"
    }
   ],
   "source": [
    "lsi = models.LsiModel.load('model.lsi') # try to load above saved model\n",
    "print(lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[(0, 1), (1, 1)]\n"
    }
   ],
   "source": [
    "doc = \"Human computer interaction\"  # give new document to calculate similarity degree with already obtained topics\n",
    "\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())  # put newly obtained document to existing dictionary object\n",
    "print(vec_bow)  # show result of above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[(0, 0.07910475117444923), (1, -0.5732835243079406)]\n"
    }
   ],
   "source": [
    "vec_lsi = lsi[vec_bow] # convert new document (henceforth, call it \"query\") to LSI space\n",
    "print(vec_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MatrixSimilarity<9 docs, 2 features>\n"
    }
   ],
   "source": [
    "index = similarities.MatrixSimilarity(lsi[corpus]) # transform corpus to LSI space and indexize it\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.save('deerwester.index') # save index object at local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = similarities.MatrixSimilarity.load('deerwester.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MatrixSimilarity<9 docs, 2 features>\n"
    }
   ],
   "source": [
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[ 0.9999408   0.9946708   0.9999428   0.999879    0.99935204 -0.08804217\n -0.0515742  -0.02366471  0.1938726 ]\n"
    }
   ],
   "source": [
    "sims = index[vec_lsi] # calculate degree of similarity of the query to existing corpus\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[(0, 0.9999408), (1, 0.9946708), (2, 0.9999428), (3, 0.999879), (4, 0.99935204), (5, -0.08804217), (6, -0.0515742), (7, -0.023664713), (8, 0.1938726)]\n"
    }
   ],
   "source": [
    "print(list(enumerate(sims))) # output (document_number , document similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[(2, 0.9999428), (0, 0.9999408), (3, 0.999879), (4, 0.99935204), (1, 0.9946708), (8, 0.1938726), (7, -0.023664713), (6, -0.0515742), (5, -0.08804217)]\n"
    }
   ],
   "source": [
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])  # sort output object as per similarity ( largest similarity document comes first )\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bitdf6fafea6f864b21882d7b87f917e4eb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}