{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import utils\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaggedDocument(['the', 'clumsy', 'and', 'unfunny', 'clown', 'richard', '``', 'stitches', \"''\", 'grindle', 'entertains', 'at', 'the', '10th', 'birthday', 'party', 'of', 'little', 'tom', 'but', 'the', 'boy', 'and', 'his', 'friends', 'play', 'prank', 'with', 'stitches', 'tying', 'his', 'shoelaces', 'stitches', 'slips', 'falls', 'and', 'dies', 'six', 'years', 'later', 'tom', 'gives', 'birthday', 'party', 'for', 'his', 'friends', 'at', 'home', 'but', 'stitches', 'revives', 'to', 'haunt', 'the', 'teenagers', 'and', 'revenge', 'his', 'death'], [3])\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "# Function for tokenizing\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens\n",
    "# Initializing the variables\n",
    "train_documents = []\n",
    "test_documents = []\n",
    "'''i = 0\n",
    "# Associating the tags(labels) with numbers\n",
    "tags_index = {'sci-fi': 1 , 'action': 2, 'comedy': 3, 'fantasy': 4, 'animation': 5, 'romance': 6}\n",
    "#Reading the file\n",
    "#FILEPATH = 'tagged_plots_movielens.csv'\n",
    "#with open(FILEPATH, 'r') as csvfile:\n",
    "with open('tagged_plots_movielens.csv', 'r') as csvfile:\n",
    "    moviereader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    for row in moviereader:\n",
    "        if i == 0:\n",
    "            i += 1\n",
    "            continue\n",
    "        i += 1\n",
    "        if i <= 2000:\n",
    "            train_documents.append(TaggedDocument(words=tokenize_text(row[2]), tags=[tags_index.get(row[3], 8)] ))\n",
    "        else:\n",
    "            test_documents.append( TaggedDocument(words=tokenize_text(row[2]),\n",
    " tags=[tags_index.get(row[3], 8)]))'''\n",
    "\n",
    "categories = ['action_adventure','drama_romance','comedy_family','horror_thriller']\n",
    "tmdbmovies_train = pd.read_csv(\"total_train.csv\")\n",
    "tmdbmovies_test = pd.read_csv(\"total_test.csv\")\n",
    "for i in range(len(tmdbmovies_train.data)):\n",
    "    train_documents.append(TaggedDocument(words=tokenize_text(tmdbmovies_train[\"data\"][i]),tags=[tmdbmovies_train[\"Label\"][i]]))\n",
    "for j in range(len(tmdbmovies_test.data)):\n",
    "    test_documents.append(TaggedDocument(words=tokenize_text(tmdbmovies_test[\"data\"][j]),tags=[tmdbmovies_test[\"Label\"][j]]))\n",
    "\n",
    "print(train_documents[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 2400/2400 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.doc2vec.Doc2Vec at 0x19e6138df98>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=1, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, alpha=0.025, min_alpha=0.001)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_documents)])\n",
    "train_documents  = utils.shuffle(train_documents)\n",
    "model_dbow.train(train_documents,total_examples=len(train_documents), epochs=30)\n",
    "def vector_for_learning(model, input_docs):\n",
    "    sents = input_docs\n",
    "    targets, feature_vectors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, feature_vectors\n",
    "model_dbow.save('./tmdbdoc2veclsa.d2v')\n",
    "#model_dbow = Doc2Vec.load('./movieModel.d2v')\n",
    "model_dbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_for_learning(model, input_docs):\n",
    "    sents = input_docs\n",
    "    targets, feature_vectors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, feature_vectors\n",
    "\n",
    "y_train, X_train = vector_for_learning(model_dbow, train_documents)\n",
    "y_test, X_test = vector_for_learning(model_dbow, test_documents)\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "svd = TruncatedSVD(100)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "\n",
    "X_train_lsa = lsa.fit_transform(X_train)\n",
    "X_test_lsa = lsa.transform(X_test)\n",
    "\n",
    "X_train = X_train_lsa\n",
    "X_test = X_test_lsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Doc2Vec + LSA + cosine==============\n",
      "accuracy: 0.38875\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "action_adventure       0.38      0.58      0.46       453\n",
      "   drama_romance       0.41      0.45      0.43       446\n",
      "   comedy_family       0.40      0.28      0.33       409\n",
      " horror_thriller       0.34      0.15      0.21       292\n",
      "\n",
      "        accuracy                           0.39      1600\n",
      "       macro avg       0.38      0.37      0.36      1600\n",
      "    weighted avg       0.39      0.39      0.37      1600\n",
      "\n",
      "confusion matrix:\n",
      "               action:pred  romance:pred  comedy:pred  horror:pred     All\n",
      "action:true           262            86           71           34   906.0\n",
      "romance:true          139           199           71           37   892.0\n",
      "comedy:true           148           127          116           18   818.0\n",
      "horror:true           140            76           31           45   584.0\n",
      "All                   689           488          289          134  1600.0\n",
      "accuracy: 38.875\n"
     ]
    }
   ],
   "source": [
    "knn_cos = KNeighborsClassifier(n_neighbors=5, metric='cosine')\n",
    "knn_cos.fit(X_train, y_train)\n",
    "print(\"=================Doc2Vec + LSA + cosine==============\")\n",
    "print(\"accuracy:\",knn_cos.score(X_test,y_test))\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Classify the test vectors.\n",
    "y_pred = knn_cos.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=categories))\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, y_pred),index=['action:true', 'romance:true','comedy:true','horror:true'],columns=['action:pred', 'romance:pred','comedy:pred','horror:pred'])\n",
    "cw = cm.sum(axis=0)\n",
    "cm[\"All\"] = cm.sum(axis=1)\n",
    "row_df = pd.DataFrame([cw],index=[\"All\"])\n",
    "cm = pd.concat([ cm,row_df])\n",
    "cm[\"All\"] = cm.sum(axis=1)\n",
    "print(\"confusion matrix:\\n\",cm)\n",
    "print(\"accuracy:\",metrics.accuracy_score(y_test, y_pred)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bitdf6fafea6f864b21882d7b87f917e4eb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
